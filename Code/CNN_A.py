# -*- coding: utf-8 -*-
"""NNCNN_A.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b7plGyyTPYacI56X0tTzvEbWG9XMNBEn
"""

######################################################################## imports
import pandas as pd
import math
import cv2
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision
import torchvision.datasets as datasets
from torch.autograd import Variable
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from sklearn import preprocessing
from torch.utils.data import Dataset, DataLoader
import PIL
from pathlib import Path
import os
######################################################## read age label csv file
df = pd.read_table('../Data/labelage_ALL.csv',header=None, delim_whitespace=True, names=["age"])
labelage=df['age']
########################################################### define dataset class
class FacesDataset(Dataset):
    def __init__(self, root, image_dir, csv_file, transform=None):
        self.root = root
        self.image_dir = image_dir
        self.image_files = os.listdir(image_dir)
        self.data = csv_file
        self.transform = transform
    def __len__(self):
        return len(self.data)
    def __getitem__(self, index):
        image_name = os.path.join(self.image_dir, self.image_files[index])
        image = PIL.Image.open(image_name)
        label = self.data[index]
        if self.transform:
            image = self.transform(image)
        return (image, label)
################################################# read images and transform them
root = Path(os.getcwd())
image_dir = '../Data/ALL'
csv_file = labelage
transform_img = transforms.Compose([#transforms.Resize((256,256)),
                                    transforms.RandomResizedCrop(64),           #create 64x64 image
                                    transforms.RandomHorizontalFlip(),          #flipping the image horizontally
                                    transforms.ToTensor(),                      #convert the image to a Tensor
                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
dset = FacesDataset(root, image_dir, csv_file, transform= transform_img)
dset.image_files=sorted(dset.image_files, key=lambda x: int(x.partition('.')[2].partition('.')[0]))
########################################################### train and test split
train_dataset, test_dataset = torch.utils.data.random_split(dset, [13000, 3249])
######################################### Make batches on the train/test dataset
batch_size = 2
train_load = torch.utils.data.DataLoader(dataset = train_dataset,
                                         batch_size = batch_size,
                                         shuffle = True)
batch_size = 2
test_load = torch.utils.data.DataLoader(dataset = test_dataset,
                                         batch_size = batch_size,
                                         shuffle = False)
######################################################### show data of one batch
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.figure()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
dataiter = iter(train_load)
images, labels = dataiter.next()
imshow(torchvision.utils.make_grid(images))
###################################################################### CNN class
class CNN(nn.Module):
    def __init__(self):
        super(CNN,self).__init__()
        
        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3,stride=1, padding=1)
        self.batchnorm1 = nn.BatchNorm2d(8)                                     #Batch normalization
        self.relu = nn.ReLU()                                                   #RELU Activation
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)                
        
        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)
        self.batchnorm2 = nn.BatchNorm2d(32)
        self.maxpool2 = nn.MaxPool2d(kernel_size=2)    
        
        self.fc1 = nn.Linear(in_features=8192, out_features=4000)   
        self.droput = nn.Dropout(p=0.5)                                         #Dropout used to reduce overfitting
        self.fc2 = nn.Linear(in_features=4000, out_features=2000)
        self.droput = nn.Dropout(p=0.5)
        self.fc3 = nn.Linear(in_features=2000, out_features=500)
        self.droput = nn.Dropout(p=0.5)
        self.fc4 = nn.Linear(in_features=500, out_features=50)
        self.droput = nn.Dropout(p=0.5)
        self.fc5 = nn.Linear(in_features=50, out_features=8)     
        #self.SM1=nn.Softmax()
        
    def forward(self,x):
        out = self.cnn1(x)
        out = self.batchnorm1(out)
        out = self.relu(out)
        out = self.maxpool1(out)
        out = self.cnn2(out)
        out = self.batchnorm2(out)
        out = self.relu(out)
        out = self.maxpool2(out)
        #Flattening is done here with .view() -> (batch_size, 32*16*16) = (100, 8192)
        out = out.view(-1,8192)   #-1 will automatically update the batchsize as 100; 8192 flattens 32,16,16
        #Then we forward through our fully connected layer 
        out = self.fc1(out)
        out = self.relu(out)
        out = self.droput(out)
        out = self.fc2(out)
        out = self.relu(out)
        out = self.droput(out)
        out = self.fc3(out)
        out = self.relu(out)
        out = self.droput(out)
        out = self.fc4(out)
        out = self.relu(out)
        out = self.droput(out)
        out = self.fc5(out)
        #out = self.SM1(out)
        return out
################################################################################ 
model = CNN()
CUDA = torch.cuda.is_available()
if CUDA:
    model = model.cuda()    
loss_fn = nn.CrossEntropyLoss()        
optimizer = torch.optim.SGD(model.parameters(), lr =math.exp( -3 ))

############################################################### training the CNN 
num_epochs = 200
#Define the lists to store the results of loss and accuracy
train_loss = []
test_loss = []
train_accuracy = []
test_accuracy = []
#Training
for epoch in range(num_epochs): 
    #Reset these below variables to 0 at the begining of every epoch
    #start = time.time()
    correct = 0
    if epoch>100:                                                                                                                                 
      for g in optimizer.param_groups:                                                                           
        g['lr'] = math.exp( -4 )                                                                                 
    print(optimizer.param_groups[0]['lr'])                                                                       
    iterations = 0
    iter_loss = 0.0

    model.train()                   # Put the network into training mode
    for i, (inputs, labels) in enumerate(train_load):
        #print(i)
        # Convert torch tensor to Variable
        inputs = Variable(inputs)
        labels = Variable(labels)
        #print(inputs)
        #print(labels)
        # If we have GPU, shift the data to GPU
        CUDA = torch.cuda.is_available()
        if CUDA:
            inputs = inputs.cuda()
            labels = labels.cuda()
        optimizer.zero_grad()            # Clear off the gradient in (w = w - gradient)
        outputs = model(inputs) 
        #print(outputs)
        labels=labels.long()
        #print(labels)
        loss = loss_fn(outputs, labels)  
        iter_loss += loss.item()       # Accumulate the loss
        loss.backward()                 # Backpropagation 
        optimizer.step()                # Update the weights
        # Record the correct predictions for training data 
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum()
        iterations += 1
    #print(correct)
    #print(len(train_dataset))
    # Record the training loss
    train_loss.append(iter_loss/iterations)
    # Record the training accuracy
    train_accuracy.append((100 * correct / len(train_dataset)))
    #Testing
    loss = 0.0
    correct = 0
    iterations = 0
    print ('Epoch {}/{}, Vaidation Loss: {:.3f}, Vaidation Acc: {:.3f}'
           .format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1]))
###################################################################### plot Loss
f = plt.figure(figsize=(10, 10))
plt.plot(train_loss, label='Training Loss')
plt.legend()
plt.show()

# Accuracy
f = plt.figure(figsize=(10, 10))
plt.plot(train_accuracy, label='Training Accuracy')
plt.legend()
plt.show()
############################################################# result on test set
model.eval()                    
correct_on_test = 0
total_on_test = 0    
for i, (inputs, labels) in enumerate(test_load):
        # Convert torch tensor to Variable
        #inputs = Variable(inputs)
        #labels = Variable(labels)
  CUDA = torch.cuda.is_available()
  if CUDA:
    inputs = inputs.cuda()
    labels = labels.cuda()
  outputs = model(inputs)     
  _, predicted = torch.max(outputs, 1)
  #total_on_test += labels.size(0)
  correct_on_test += (predicted == labels).sum().item()
total_on_test=3249
print(correct_on_test)
print(100*(correct_on_test / total_on_test))